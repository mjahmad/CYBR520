{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95780470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code generates synthetic data, applies three different anomaly detection techniques (OC-SVM, Isolation Forest, LOF), \n",
    "# and evaluates their performance using various metrics. \n",
    "# Keep in mind that the choice of parameters and the quality of the synthetic data can impact the results,\n",
    "# and in practice, real-world data should be used for a more accurate assessment of these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "994bcec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2d67e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1939bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Synthetic DataWe create a synthetic dataset using make_blobs. \n",
    "# This dataset contains two clusters, and we introduce 30 outlier points manually.\n",
    "\n",
    "X, y = make_blobs(n_samples=300, centers=2, random_state=42, cluster_std=1.0)\n",
    "outliers = np.random.uniform(low=-10, high=10, size=(30, 2))\n",
    "X = np.vstack([X, outliers])\n",
    "y = np.hstack([y, [-1] * len(outliers)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e657d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "# We split the data into training (X_train, y_train) and testing (X_test, y_test) sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "089ed2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-class SVM (OC-SVM)\n",
    "# We create an OC-SVM model with a contamination rate of 5% \n",
    "# (meaning we expect 5% of data to be outliers). We train it on the training data and make predictions on the test data.\n",
    "\n",
    "ocsvm = OneClassSVM(nu=0.05)\n",
    "ocsvm.fit(X_train)\n",
    "y_pred_ocsvm = ocsvm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "317f7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest\n",
    "iforest = IsolationForest(contamination=0.05, random_state=42)\n",
    "iforest.fit(X_train)\n",
    "y_pred_iforest = iforest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95d450b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an Isolation Forest model with the same contamination rate as OC-SVM. \n",
    "# We fit it to the training data and make predictions on the test data.\n",
    "iforest = IsolationForest(contamination=0.05, random_state=42)\n",
    "iforest.fit(X_train)\n",
    "y_pred_iforest = iforest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc0c5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Outlier Factor (LOF)\n",
    "# We create an LOF model with a contamination rate of 5% and set \n",
    "# the number of neighbors to consider as 20. We fit it to the test data and predict anomalies.\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "y_pred_lof = lof.fit_predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e6343de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics:\n",
    "#     We define a function evaluate to assess model performance.\n",
    "#    We print the confusion matrix (although it may not be very informative for unsupervised anomaly detection).\n",
    "#    We display a classification report showing precision, recall, F1-score, and support for each class \n",
    "#    (anomaly and non-anomaly).\n",
    "#    We calculate the AUC-ROC score and plot the ROC curve if applicable.\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    # Confusion Matrix\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "    # AUC-ROC\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(f\"\\nAUC-ROC: {roc_auc}\")\n",
    "        # Plot ROC curve\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        # Other ROC curve settings\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    except ValueError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "457ad70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-class SVM Results:\n",
      "Confusion Matrix:\n",
      " [[ 4  0  3]\n",
      " [ 0  0 27]\n",
      " [ 0  0 32]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.57      0.73         7\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.52      1.00      0.68        32\n",
      "\n",
      "    accuracy                           0.55        66\n",
      "   macro avg       0.51      0.52      0.47        66\n",
      "weighted avg       0.36      0.55      0.41        66\n",
      "\n",
      "\n",
      "Isolation Forest Results:\n",
      "Confusion Matrix:\n",
      " [[ 5  0  2]\n",
      " [ 0  0 27]\n",
      " [ 0  0 32]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.71      0.83         7\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.52      1.00      0.69        32\n",
      "\n",
      "    accuracy                           0.56        66\n",
      "   macro avg       0.51      0.57      0.51        66\n",
      "weighted avg       0.36      0.56      0.42        66\n",
      "\n",
      "\n",
      "Local Outlier Factor (LOF) Results:\n",
      "Confusion Matrix:\n",
      " [[ 4  0  3]\n",
      " [ 0  0 27]\n",
      " [ 0  0 32]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.57      0.73         7\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.52      1.00      0.68        32\n",
      "\n",
      "    accuracy                           0.55        66\n",
      "   macro avg       0.51      0.52      0.47        66\n",
      "weighted avg       0.36      0.55      0.41        66\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\envs\\pythonCYBR520\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\miniconda3\\envs\\pythonCYBR520\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\miniconda3\\envs\\pythonCYBR520\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\miniconda3\\envs\\pythonCYBR520\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\miniconda3\\envs\\pythonCYBR520\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\miniconda3\\envs\\pythonCYBR520\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\miniconda3\\envs\\pythonCYBR520\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\miniconda3\\envs\\pythonCYBR520\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\miniconda3\\envs\\pythonCYBR520\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "\n",
    "print(\"One-class SVM Results:\")\n",
    "evaluate(y_test, y_pred_ocsvm)\n",
    "\n",
    "print(\"\\nIsolation Forest Results:\")\n",
    "evaluate(y_test, y_pred_iforest)\n",
    "\n",
    "print(\"\\nLocal Outlier Factor (LOF) Results:\")\n",
    "evaluate(y_test, y_pred_lof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1f4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f08924",
   "metadata": {},
   "outputs": [],
   "source": [
    "i see a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonCYBR520",
   "language": "python",
   "name": "pythoncybr520"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
